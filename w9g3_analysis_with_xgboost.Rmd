---
title: "Week 9"
author: "Group 3: Mara Alexeev, Parker Bannister, Mitchell Flagg"
date: "November 9, 2020"
output: html_document

---


**Deliverables:**

Code available at our github repo: [MaraAlexeev/720_regex_mmp](https://github.com/MaraAlexeev/720_regex_mmp)

[Error analysis](#eval) of the top 10 false positive and false negative terms

Model Output - group3_predictions_wk9.csv




# Libraries
```{r libraries, warning=FALSE, message=FALSE}
#get relevant libraries
library(tidyverse)
library(forcats)
#install.packages("caret")
#library(caret)
#install.packages("rlang")
#install.packages("cvms")
#install.packages("cvms")
library(cvms)
#install.packages("tidyr")
library(tidyr)
#library(broom)    
library(tibble)   
#install.packages("here")
library(here)
#library(tidytext)
#install.packages("ggimage")
library(ggimage)
#install.packages("rsvg")
library(rsvg)
#library(textstem)
library(text2vec)
library(data.table)

#install.packages("glmnet")
#library(glmnet)
library(ROCR)
library(pROC)
library(caTools)
library(tm)
library(SnowballC)
```

# Functions
```{r custom functions}

search_assign_by_cc <- function(data, search_terms, column_to_search) {
  pasted_match <- paste(search_terms, collapse = "|")
  
  searched_and_assigned <- data %>%
  mutate(covid_guess = as.integer(grepl(pattern = pasted_match, x = column_to_search, ignore.case = TRUE))) 
  
  return(searched_and_assigned)
}

covid_prediction_count <- function(data) {
  prediction_count <- data %>% 
  group_by(covid_guess) %>%
  summarise(count = n())
  
  return(prediction_count)
}

covid_model_comparison <- function(data_predictions, data_w_labels) {
  only_labeled_rows <- data_w_labels %>%
    filter(label == "0"| label == "1")
  
  joined_data <- only_labeled_rows %>%
  left_join(data_predictions, by = "id") 
  
  joined_data$label <- as.numeric(joined_data$label)
  
  renamed_joined_data <- joined_data %>% 
  rename(
    covid_status = label,
    covid_prediction = covid_guess
    )
  
  error_analysis <- renamed_joined_data %>%
 mutate(results =  case_when(
    covid_status == 0 & covid_prediction == 0 ~ "True Negative",
    covid_status == 1 & covid_prediction == 1 ~ "True Positive",
    covid_status == 0 & covid_prediction == 1 ~ "False Positive",
    covid_status == 1 & covid_prediction == 0 ~ "False Negative"
  )
 )
  return(error_analysis)
}

covid_model_comparison_table <- function(data_with_status_and_prediction){
  real_and_prediction <- data_with_status_and_prediction %>%
  group_by(covid_status, covid_prediction) %>%
  summarise(count = n())
  
   return(real_and_prediction)
}

evaluation_table <- function(covid_model){

model_basic_table <- data.frame("target" = c(covid_model$covid_status),
                                  "prediction"= c(covid_model$covid_prediction)) 

model_eval <- evaluate(model_basic_table,
                 target_col = "target",
                 prediction_col = "prediction",
                 type = "binomial")

return(model_eval)
}

#Function to sort results by cc

cc_by_results <- function(model, results_factor, cc_number_to_return = 10) {
  results_filtered <- model %>%
  filter(results == results_factor)
  
  top_cc <- results_filtered%>%
  group_by(results, grouped_cc) %>%
  summarise(count = n()) %>% 
  arrange(desc(count)) %>%
  head(cc_number_to_return)
  

  return(print(top_cc))
}
```

## Load data files
```{r load files, warning=FALSE, message=FALSE}
#read in data
# covidclass_without_labels <- read.table("./data_do_not_alter/covidclass_without_labels.csv",
#                                         na.strings = "", header = TRUE, sep = "\t")
# 
# covidclass_w_labels <- read.table("./data_do_not_alter/covidclass_30_percent_labels.csv",
#                                         na.strings = "", header = TRUE, sep = "\t")

covidclass_70percentlabels <- read.table("data_do_not_alter/covidclass_70percentlabels.csv",  na.strings = "", header = TRUE, sep = "|", quote = "", comment.char = "", col.names = c("id", "chief_complaint_1", "chief_complaint_2", "thirty_label", "seventy_label"))
```

## Clean Data
```{r clean data}

#Cleaning rows 4010 and 6713 with extra quotation marks
covidclass_70percentlabels[4010,1] <- 4010 
covidclass_70percentlabels[4010,5] <- 0 
covidclass_70percentlabels[6713,1] <- 6713
covidclass_70percentlabels[6713,5] <- 0 

#Making empty chief complaint clearer
covidclass_70percentlabels$chief_complaint_1[which(is.na(covidclass_70percentlabels$chief_complaint_1))] <-  "No CC provided"


covidclass_70percentlabels$id <- as.numeric(covidclass_70percentlabels$id)

```


```{r combine ccs}

#Combine concepts that are similar but different encodings of the same chief complaint to account for different spellings and misspellings or abbreviations

sob_concept <- c("SOB", 	"SOB - SHORTNESS OF BREATH", "SHORT OF BREATH", "SHORT OF BREATHE", "SHORTNESS OF BREATH")
fever_concept <- c("FEVER", "FEVERS")
ili_concept <- c("\\bILI\\b", "FLU", "FLU-LIKE SYMPTOMS", "ILI - INFLUENZE LIKE ILLNESS", 	"INFLUENZA LIKE ILLNESS", "INFLUENZA", "I L I", "ILI")
cough_concept <- c("COUGH", "COUGH/CONGESTION", "Productive cough", "PRODUCTIVE COUGH")
hypoxia_concept <- c("HYPOXEMIA", "HYPOXIA", "HYPOXIC")
dyspnea_concept <- c("DYPNEA", "DYSPNEA")
doe_concept <- c("DOE - DYSPNEA ON EXERTION", "DYSPNEA ON EXERTION")
resp_dis_concept <- c("RESP DISTRESS", 	"RESPIRATORY DISTRESS")

combined_cc_data <- covidclass_70percentlabels %>% 
  mutate(grouped_cc = case_when(
    chief_complaint_1 %in% sob_concept ~ "shortness of breath",
    chief_complaint_1 %in% fever_concept ~ "fever",
    chief_complaint_1 %in% ili_concept ~ "ili",
    chief_complaint_1 %in% cough_concept ~ "cough",
    chief_complaint_1 %in% hypoxia_concept ~ "hypoxia",
    chief_complaint_1 %in% dyspnea_concept ~ "dyspnea",
    chief_complaint_1 %in% doe_concept ~ "doe",
    chief_complaint_1 %in% resp_dis_concept ~ "respiratory distress",
    TRUE                           ~ .$chief_complaint_1
    )
  )

week_9_labeled_data <- combined_cc_data %>% 
  filter(!is.na(seventy_label)) %>%  
  mutate(covid_label = case_when(
    seventy_label == "0" ~ 0,
    seventy_label == "1" ~ 1
  ))


week_9_predictions <- combined_cc_data %>% 
    mutate(covid_label = case_when(
    seventy_label == "0" ~ 0,
    seventy_label == "1" ~ 1
  ))
```




```{r corpus creation}
#https://www.pluralsight.com/guides/machine-learning-text-data-using-r

corpus <-  Corpus(VectorSource(week_9_labeled_data$grouped_cc))
corpus[[1]][1]  

corpus <-  tm_map(corpus, PlainTextDocument)

corpus  <-  tm_map(corpus, tolower)
  

corpus <- tm_map(corpus, removePunctuation)
corpus[[1]][1]  

corpus <-  tm_map(corpus, removeWords, c(stopwords("english")))
corpus[[1]][1] 

corpus <-  tm_map(corpus, stemDocument)
corpus[[1]][1] 

frequencies  <-  DocumentTermMatrix(corpus)

sparse <-  removeSparseTerms(frequencies, 0.995)

tSparse <-  as.data.frame(as.matrix(sparse))
colnames(tSparse) <-  make.names(colnames(tSparse))

columns_to_keep <- colnames(tSparse)

tSparse$covid_label <-  week_9_labeled_data$covid_label
```

```{r}
prop.table(table(tSparse$covid_label))
```
```{r divide to test and train}

set.seed(888)
split  <-  sample.split(tSparse$covid_label, SplitRatio = 0.7)
trainSparse  <-  subset(tSparse, split==TRUE)
testSparse <-  subset(tSparse, split==FALSE)


```

```{r}

 
# k <- 0.99999
# RF_model  <-  randomForest(covid_label ~ ., data=trainSparse, importance = TRUE, cutoff = c(k, 1-k))
# varImpPlot(RF_model)
# 
# predictRF <-  predict(RF_model, newdata=testSparse)
# table(testSparse$covid_label, predictRF)
#  

```
## Trying something new
Searching online found that the randomForest() does not work well with sparse data or data with just one variable. Here we try `xgboost`.

```{r, warning=FALSE, message=FALSE}
require(xgboost)
require(Matrix)
require(data.table)

```

```{r}


#sparse_matrix <- sparse.model.matrix(covid_label ~ ., data = trainSparse)[,-1]

#Drop the covid_label from being in the training
data_matrix <- as.matrix(trainSparse[,colnames(trainSparse) != "covid_label"])
output_vector  <-  as.matrix(trainSparse[,"covid_label"]) 

bst <- xgboost(data = data_matrix, label = output_vector, scale_pos_weight = 20, nrounds = 20,objective = "binary:logistic")
```




```{r}

data_matrix_test <- as.matrix(testSparse[,colnames(testSparse) != "covid_label"])

pred <- predict(bst, data_matrix_test)

prediction <- as.numeric(pred > 0.5)
```

```{r}

test_data <- data.frame(testSparse)
test_data <- rownames_to_column(test_data, var = "id")
prediction <- data.frame(prediction)

data_and_prediction <-cbind(test_data, prediction)

small_d_and_p <- data_and_prediction %>% 
  select("id", "prediction", "covid_label")
table(small_d_and_p$prediction, small_d_and_p$covid_label)
```
```{r}
corpus_f <-  Corpus(VectorSource(week_9_predictions$grouped_cc))

corpus_f <-  tm_map(corpus_f, PlainTextDocument)

corpus_f  <-  tm_map(corpus_f, tolower)

corpus_f <- tm_map(corpus_f, removePunctuation)


corpus_f <-  tm_map(corpus_f, removeWords, c(stopwords("english")))

corpus_f <-  tm_map(corpus_f, stemDocument)
 

frequencies_f  <-  DocumentTermMatrix(corpus_f)

frequencies_f_all_columns <-  as.data.frame(as.matrix(frequencies_f))

full_data_top_columns <- frequencies_f_all_columns %>% 
  select(columns_to_keep)


full_data_top_columns$covid_label <-  (week_9_predictions$covid_label)

data_matrix_full <- as.matrix(full_data_top_columns[,colnames(full_data_top_columns) != "covid_label"])

pred_full <- predict(bst, data_matrix_full)
pred_full <- data.frame(pred_full)
```

## Predicted probabilities and cutoff
```{r}
week_9_predictions$predictions <- pred_full$pred_full

cut_off_w9 <- 0.5
week_9_predictions <- week_9_predictions %>% 
  mutate(final_prediction_w9 = case_when(
    predictions >= cut_off_w9 ~ 1,
    predictions < cut_off_w9 ~ 0,
  ))

week_9_predictions_errors <- week_9_predictions %>% 
  filter(!is.na(covid_label))

table(week_9_predictions_errors$covid_label, week_9_predictions_errors$final_prediction_w9)
```
## ROC curves
```{r}
pred_week_9 <- prediction(week_9_predictions_errors$final_prediction_w9, week_9_predictions_errors$covid_label)
perf_week_9 <- performance(pred_week_9,"tpr","fpr")
plot(perf_week_9,colorize=FALSE)
```
```{r}
pROC_obj <- roc(week_9_predictions_errors$final_prediction_w9, week_9_predictions_errors$covid_label,
            smoothed = TRUE,
            # arguments for ci
            ci=TRUE, ci.alpha=0.9, stratified=FALSE,
            # arguments for plot
            plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
            print.auc=TRUE, show.thres=TRUE)


sens.ci <- ci.se(pROC_obj)
plot(sens.ci, type="shape", col="lightblue")
## Warning in plot.ci.se(sens.ci, type = "shape", col = "lightblue"): Low
## definition shape.
plot(sens.ci, type="bars")
```


```{r}
model_w9 <- data.frame("target" = c(week_9_predictions_errors$covid_label),
                                  "prediction"= c(week_9_predictions_errors$final_prediction_w9)) 

model_eval_w9 <- evaluate(model_w9,
                 target_col = "target",
                 prediction_col = "prediction",
                 type = "binomial")

```


# Comparison to week 8
```{r}
model_eval_w9[,1:7]
```

Week 8 results on test: 


* sensitivity    0.285714286
* specificity    0.864125122
* PPV    0.122105263
* NPV    0.948158742
* accuracy    0.828239609
* f1    0.171091445


```{r}
plot_confusion_matrix(model_eval_w9, palette = "Greens")
```



# Error Analysis {#eval}


```{r}
error_analysis <- week_9_predictions_errors %>%
 mutate(results =  case_when(
    covid_label == 0 & final_prediction_w9 == 0 ~ "True Negative",
    covid_label == 1 & final_prediction_w9 == 1 ~ "True Positive",
    covid_label == 0 & final_prediction_w9 == 1 ~ "False Positive",
    covid_label == 1 & final_prediction_w9 == 0 ~ "False Negative"
  ))
```

```{r, message = FALSE}

tp_model_1 <- cc_by_results(error_analysis, "True Positive")
tn_model_1 <- cc_by_results(error_analysis, "True Negative") 
fp_model_1 <- cc_by_results(error_analysis, "False Positive") 
fn_model_1 <- cc_by_results(error_analysis, "False Negative") 

all_results_model_1 <- bind_rows(tp_model_1, tn_model_1, fp_model_1, fn_model_1)

all_results_model_1_wide <- pivot_wider(all_results_model_1, names_from = results, values_from = count, values_fill = 0)




```

## Thoughts

Overall it seems like a non-linear classifier is more of a black box when it comes to understanding the predicted scores for the different chief complaints. The linear model was easier and faster to build and run. However, because it could oversimplfy the relationship of inputs and responses, it might miss out on more complicated relationships one can find with non-linear models. Non-linear models are however prone to overfitting training data and can then perform much worse than expected on new data inputs.


## Model Output
```{r}
#Our COVID prediction is labeled in the column "final_prediction_w9"
group3_predictions_wk9 <- week_9_predictions 
write_csv(group3_predictions_wk9, "./analysis/group3_predictions_wk9.csv")
```

### Session Information
```{r session information}
sessionInfo()
```
